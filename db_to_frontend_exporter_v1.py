import json
import os
import time
import re
from pymongo import MongoClient
from datetime import datetime, timedelta
from kiwipiepy import Kiwi  # KoNLPy ëŒ€ì‹  ì‚¬ìš©
from collections import Counter
from dotenv import load_dotenv

# [1. í™˜ê²½ ì„¤ì • ë° DB ì—°ê²°]
load_dotenv()
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = os.getenv("DB_NAME")

client = MongoClient(MONGO_URI)
db = client[DB_NAME]
EXPORT_DIR = "data_export"

# Kiwi ì´ˆê¸°í™” (ì‚¬ìš©ì ì‚¬ì „ ì¶”ê°€ë‚˜ ì˜µì…˜ ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤)
kiwi = Kiwi()

# ë¶„ì„ ì‹œ ì œì™¸í•  ì •ì¹˜ ë„ë©”ì¸ ë¶ˆìš©ì–´ (KiwiëŠ” ë¶„ì„ ëŠ¥ë ¥ì´ ì¢‹ì•„ ë¶ˆìš©ì–´ë¥¼ ì¤„ì—¬ë„ ì˜ ì‘ë™í•©ë‹ˆë‹¤)
STOPWORDS = ['ì˜ì›', 'êµ­íšŒì˜ì›', 'ë‰´ìŠ¤', 'ì˜¤ëŠ˜', 'ê¸°ì', 'ì •ì¹˜', 'êµ­íšŒ', 'ì§€ë‚œ', 'ì˜¤ì „', 'ì˜¤í›„', 'ë•Œë¬¸', 'ëŒ€í•œ', 'ê´€ë ¨', 'ì˜ìƒ', 'ì±„ë„', 'ê¸ˆì§€', 'ë¬´ë‹¨', 'ë°°í¬', 'ì¬ë°°í¬', 'ì´ë²ˆ', 'ê²½ìš°', 'í†µí•´']

def get_news_trend(news_list):
    """ìµœê·¼ 7ì¼ê°„ì˜ ë‚ ì§œë³„ ë‰´ìŠ¤ ê°œìˆ˜ ì§‘ê³„"""
    today = datetime.now().date()
    date_range = [(today - timedelta(days=i)).isoformat() for i in range(6, -1, -1)]
    trend_dict = {d: 0 for d in date_range}
    
    for news in news_list:
        p_date = news.get('pubDate')
        if isinstance(p_date, datetime):
            p_date_str = p_date.date().isoformat()
        elif isinstance(p_date, str):
            p_date_str = p_date[:10]
        else:
            continue
            
        if p_date_str in trend_dict:
            trend_dict[p_date_str] += 1
            
    return {
        "labels": [d[5:] for d in date_range],
        "data": [trend_dict[d] for d in date_range]
    }

def format_mongo_data(data):
    """MongoDB íŠ¹ìˆ˜ ê°ì²´ë¥¼ í‘œì¤€ JSON íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(data, list):
        return [format_mongo_data(item) for item in data]
    if isinstance(data, dict):
        new_dict = {}
        for k, v in data.items():
            if k == "_id":
                new_dict[k] = str(v)
            elif isinstance(v, datetime):
                new_dict[k] = v.isoformat()
            elif isinstance(v, (dict, list)):
                new_dict[k] = format_mongo_data(v)
            else:
                new_dict[k] = v
        return new_dict
    return data

def extract_member_keywords(news_list, video_list, member_name):
    """Kiwië¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    raw_text = ""
    # ì œëª© ê°€ì¤‘ì¹˜ ë¶€ì—¬ (2ë²ˆ ë°˜ë³µ)
    for n in news_list: 
        raw_text += f" {n.get('title', '')*2} {n.get('description', '')}"
    for v in video_list: 
        raw_text += f" {v.get('title', '')*2} {v.get('description', '')}"
    
    if not raw_text.strip():
        return {"top_keywords": [], "keyword_details": []}

    # Kiwi í˜•íƒœì†Œ ë¶„ì„
    # NNG(ì¼ë°˜ ëª…ì‚¬), NNP(ê³ ìœ  ëª…ì‚¬) ì¶”ì¶œ
    result = kiwi.tokenize(raw_text)
    
    # 2ê¸€ì ì´ìƒ + ëª…ì‚¬ë¥˜ + ë¶ˆìš©ì–´ ì œì™¸ + ì˜ì› ì´ë¦„ ì œì™¸
    nouns = [
        t.form for t in result 
        if t.tag in ['NNG', 'NNP'] and len(t.form) > 1 
        and t.form not in STOPWORDS 
        and t.form != member_name
    ]
    
    # ìƒìœ„ 15ê°œ í‚¤ì›Œë“œ ì‚°ì¶œ
    keyword_counts = Counter(nouns).most_common(15)
    return {
        "top_keywords": [word for word, count in keyword_counts],
        "keyword_details": [{"text": word, "value": count} for word, count in keyword_counts]
    }

def export_integrated_insight():
    if not os.path.exists(EXPORT_DIR):
        os.makedirs(EXPORT_DIR)
        print(f"ğŸ“‚ í´ë” ìƒì„± ì™„ë£Œ: {EXPORT_DIR}")

    print(f"\nğŸš€ [START] 22ëŒ€ êµ­íšŒ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ (Kiwi Engine)")
    print("=" * 80)
    
    # 1. 22ëŒ€ ì˜ì› ë¡œë“œ
    members = list(db.members.find({"is_22nd": True}))
    total_members = len(members)
    
    if total_members == 0:
        print("âš ï¸ [ERROR] DBì— 22ëŒ€ ì˜ì› ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë©”ì¸ í˜ì´ì§€ìš© ì „ì²´ ëª…ë‹¨ ì €ì¥
    with open(os.path.join(EXPORT_DIR, "members_all.json"), 'w', encoding='utf-8') as f:
        json.dump(format_mongo_data(members), f, ensure_ascii=False, indent=4)
    print(f"âœ… [MAIN] members_all.json ìƒì„± ì™„ë£Œ")

    start_time = time.time()

    # 2. ì˜ì›ë³„ ê°œë³„ ë¶„ì„ ë° íŒŒì¼ ìƒì„±
    for i, member in enumerate(members, 1):
        naas_cd = member.get('NAAS_CD')
        name = member.get('HG_NM') or member.get('NAAS_NM') # í•„ë“œëª… ëŒ€ì‘
        
        if not naas_cd: continue

        print(f"ğŸ“¦ [{i}/{total_members}] ë¶„ì„ ì¤‘: {name} ({naas_cd})", end=" ", flush=True)

        # ë°ì´í„° ì·¨í•©
        news = list(db.news.find({"related_members": naas_cd}).sort("pubDate", -1).limit(30))
        videos = list(db.youtube_videos.find({"MONA_CD": naas_cd}).sort("upload_date", -1).limit(20))

        # AI í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰ (Kiwi)
        analysis_res = extract_member_keywords(news, videos, name)

        # ë°ì´í„° êµ¬ì¡°í™”
        combined_data = {
            "profile": format_mongo_data(member),
            "analysis": {
                "keywords": analysis_res["top_keywords"],
                "keyword_frequency": analysis_res["keyword_details"],
                "last_analyzed_at": datetime.now().isoformat(),
                "trend_news": get_news_trend(news),
            },
            "recent_news": format_mongo_data(news),
            "recent_videos": format_mongo_data(videos),
            "exported_at": datetime.now().isoformat()
        }
        
        # ê°œë³„ JSON ì €ì¥
        file_path = os.path.join(EXPORT_DIR, f"{naas_cd}.json")
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=4)
        
        kw_str = ', '.join(analysis_res['top_keywords'][:3])
        print(f" -> âœ… ì™„ë£Œ ({kw_str})")

    duration = time.time() - start_time
    print("\n" + "=" * 80)
    print(f"ğŸ [FINISH] ì´ {total_members}ëª… ë¶„ì„ ì™„ë£Œ. ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ")

if __name__ == "__main__":
    export_integrated_insight()