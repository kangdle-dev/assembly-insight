import os
import json
import urllib.request
import time
import sys
import re
from pymongo import MongoClient, UpdateOne
from dotenv import load_dotenv
from datetime import datetime

# [1. í™˜ê²½ ë° ì„¤ì • ë¡œë“œ]
load_dotenv()
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = os.getenv("DB_NAME")

client = MongoClient(MONGO_URI)
db = client[DB_NAME]
news_col = db['news']
members_col = db['members']

# [2. ê²€ì¦ëœ ë©”ì´ì € ì–¸ë¡ ì‚¬ í•„í„°ë§ ë§µ]
# ì´ ëª©ë¡ì— í¬í•¨ëœ ë„ë©”ì¸ì˜ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘ ëŒ€ìƒì´ ë©ë‹ˆë‹¤.
TRUSTED_PRESS_MAP = {
    "yonhapnews.co.kr": "ì—°í•©ë‰´ìŠ¤",
    "chosun.com": "ì¡°ì„ ì¼ë³´",
    "hani.co.kr": "í•œê²¨ë ˆ",
    "khan.co.kr": "ê²½í–¥ì‹ ë¬¸",
    "donga.com": "ë™ì•„ì¼ë³´",
    "joins.com": "ì¤‘ì•™ì¼ë³´",
    "jtbc.co.kr": "JTBC",
    "sbs.co.kr": "SBS",
    "kbs.co.kr": "KBS",
    "mbc.co.kr": "MBC",
    "newsis.com": "ë‰´ì‹œìŠ¤",
    "sedaily.com": "ì„œìš¸ê²½ì œ",
    "hankyung.com": "í•œêµ­ê²½ì œ",
    "mk.co.kr": "ë§¤ì¼ê²½ì œ",
    "segye.com": "ì„¸ê³„ì¼ë³´",
    "kmib.co.kr": "êµ­ë¯¼ì¼ë³´",
    "munhwa.com": "ë¬¸í™”ì¼ë³´",
    "ytn.co.kr": "YTN",
    "news1.kr": "ë‰´ìŠ¤1",
    "nocutnews.co.kr": "ë…¸ì»·ë‰´ìŠ¤",
    "heraldcorp.com": "í—¤ëŸ´ë“œê²½ì œ"
}

def get_trusted_press(original_link):
    """ì›ë¬¸ ë§í¬ë¥¼ ë¶„ì„í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ëª…ì¹­ ë°˜í™˜ (í•„í„°ë§ í•µì‹¬)"""
    if not original_link:
        return None
    for domain, name in TRUSTED_PRESS_MAP.items():
        if domain in original_link:
            return name
    return None

def print_progress(current, total, name, added=0, matched=0):
    """ì‹¤ì‹œê°„ ìˆ˜ì§‘ ìƒí™© ì‹œê°í™”"""
    percent = (current / total) * 100
    bar_len = 20
    filled_len = int(bar_len * current // total)
    bar = 'â–ˆ' * filled_len + 'â–‘' * (bar_len - filled_len)
    status = f"\rğŸš€ [{bar}] {percent:>5.1f}% | {current}/{total} | {name:<4} | +ì‹ ê·œ: {added:<2} | ~ë§¤ì¹­: {matched:<2}"
    sys.stdout.write(status)
    sys.stdout.flush()

def collect_news_filtered():
    try:
        # 70ë¼ì¸ ê·¼ì²˜ì˜ ì½”ë“œ
        members = list(members_col.find({"is_22nd": True}, {"NAAS_NM": 1, "NAAS_CD": 1}))
        print(f"ì„±ê³µì ìœ¼ë¡œ {len(members)}ëª…ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì—°ê²° ì—ëŸ¬ ë°œìƒ: {e}")
    # 22ëŒ€ ì˜ì› ëª…ë‹¨ ë¡œë“œ
    members = list(members_col.find({"is_22nd": True}, {"NAAS_NM": 1, "NAAS_CD": 1}))
    member_map = {m['NAAS_NM']: m['NAAS_CD'] for m in members}
    total = len(members)

    print(f"\n{'='*75}")
    print(f"ğŸ›¡ï¸  [êµ­íšŒ ì¸ì‚¬ì´íŠ¸] ë©”ì´ì € ì–¸ë¡ ì‚¬ ì „ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ ì—”ì§„ ê°€ë™")
    print(f"ğŸ“¡ í•„í„°ë§ ê¸°ì¤€: {len(TRUSTED_PRESS_MAP)}ê°œ ì£¼ìš” ì–¸ë¡ ì‚¬")
    print(f"ğŸ“… ì‹œì‘ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*75}\n")

    overall_new = 0
    overall_mod = 0

    for i, (name, target_cd) in enumerate(member_map.items(), 1):
        print_progress(i, total, name)

        # ë„¤ì´ë²„ API ì¿¼ë¦¬ (ì˜ì›ëª… ê²€ìƒ‰)
        encText = urllib.parse.quote(f"êµ­íšŒì˜ì› {name}")
        # displayë¥¼ 50ìœ¼ë¡œ ë†’ì—¬ í•„í„°ë§ í›„ì—ë„ ì¶©ë¶„í•œ ê¸°ì‚¬ê°€ ë‚¨ë„ë¡ ì¡°ì •
        url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display=50&sort=date"
        
        req = urllib.request.Request(url)
        req.add_header("X-Naver-Client-Id", CLIENT_ID)
        req.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
        
        try:
            with urllib.request.urlopen(req) as response:
                items = json.loads(response.read().decode('utf-8')).get('items', [])
            
            ops = []
            for item in items:
                origin_link = item.get('originallink', item['link'])
                
                # ğŸš€ ì‹ ë¢° ì–¸ë¡ ì‚¬ í•„í„°ë§ ìˆ˜í–‰
                press_name = get_trusted_press(origin_link)
                if not press_name:
                    continue # ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ë§¤ì²´ëŠ” íŒ¨ìŠ¤
                
                link = item['link']
                title = item['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
                desc = item['description'].replace('<b>','').replace('</b>','').replace('&quot;','"')
                
                # ìƒí˜¸ ì°¸ì¡° ë¡œì§ (íƒ€ ì˜ì› ì–¸ê¸‰ ë§¤í•‘)
                related = [target_cd]
                for m_name, m_cd in member_map.items():
                    if m_name in title or m_name in desc:
                        related.append(m_cd)
                
                # ë„¤ì´ë²„ ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì´ì¬ datetime ê°ì²´ë¡œ ë³€í™˜
                dt_obj = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")

                ops.append(UpdateOne(
                    {"link": link},
                    {
                        "$set": {
                            "title": title, 
                            "description": desc, 
                            "pubDate": dt_obj, 
                            "originallink": origin_link,
                            "press": press_name
                        },
                        "$addToSet": {"related_members": {"$each": list(set(related))}},
                        "$setOnInsert": {"created_at": datetime.now()}
                    },
                    upsert=True
                ))

            if ops:
                res = news_col.bulk_write(ops, ordered=False)
                overall_new += res.upserted_count
                overall_mod += res.modified_count
                print_progress(i, total, name, res.upserted_count, res.modified_count)

        except Exception as e:
            print(f"\nâŒ {name} ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)[:50]}...")
            if "429" in str(e): break
            continue
        
        time.sleep(0.1)

    print(f"\n\n{'='*75}")
    print(f"ğŸ ì‹ ë¢° ë§¤ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ ë¦¬í¬íŠ¸")
    print(f"âœ¨ ì‹ ê·œ ìˆ˜ì§‘: {overall_new:,} ê±´")
    print(f"ğŸ”„ ì¤‘ë³µ ë§¤ì¹­: {overall_mod:,} ê±´")
    print(f"â±ï¸ ì¢…ë£Œì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*75}\n")

if __name__ == "__main__":
    collect_news_filtered()